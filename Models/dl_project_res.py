# -*- coding: utf-8 -*-
"""DL_Proj_Sep_Classes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ttl3H0xXe6ujhuUwA7gugqgaAGYxwUzZ
"""

### ResNet50V2 Model ###

# Commented out IPython magic to ensure Python compatibility.
import sys
import sklearn
import os
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from functools import partial
import PIL
import PIL.Image

# %tensorflow_version 2.x
import tensorflow as tf
from tensorflow import keras

np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing
tf.random.set_seed(42)

import pandas as pd
import numpy as np


# each batch in train_ds or validation_ds tensor: 32 image tensors (224 x 224 x 3); 1D tensor with 32 class labels

from sklearn.datasets import load_files 
from keras.utils import np_utils

from keras.preprocessing import image
from tqdm import tqdm # progress bar

data_dir = "/home/cew4pf/dl_project/content/test_dir/"
batch_size = 32;
# IMPORTANT: Depends on what pre-trained model you choose, you will need to change these dimensions accordingly --> change to 224 since expected size for MobileNet
img_height = 224; 
img_width = 224;

# Training Dataset
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split = 0.2,
    subset = "training",
    seed = 42,
    image_size= (img_height, img_width),
    batch_size = batch_size
)

# Validation Dataset
validation_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split = 0.2,
    subset = "validation",
    seed = 42,
    image_size = (img_height, img_width),
    batch_size = batch_size
)

"""## **Create the model**"""

from keras.applications import resnet_v2

keras.backend.clear_session()
tf.random.set_seed(42)
np.random.seed(42)

"""### **1. Configure dataset for performance**

* Buffered prefetching to load images from disk
"""

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)

validation_ds = validation_ds.prefetch(buffer_size = AUTOTUNE)

"""### **2. Data augmentation**

* Augment training data by applying transformations (e.g., flip, rotate, skew, discolor) to prevent overfitting and increase generalizability of model
* Used only on training data (not in inference mode with `model.evaluate` or `model.fit`)

"""

data_augmentation = tf.keras.Sequential([
                                         tf.keras.layers.RandomFlip('horizontal', seed = 42),
                                         tf.keras.layers.RandomRotation(0.2, seed = 42),
                                         tf.keras.layers.RandomContrast(factor = 0.5, seed = 42),
                                         tf.keras.layers.RandomTranslation(height_factor = 0.2, width_factor = 0.2, fill_mode = "reflect", seed = 42)
])

"""### **3. Rescale pixel values**

* Training, validation dataset pixel values between 0 and 255 (color images) $\rightarrow$ `MobileNet` requires in `[-1,1]`
"""

preprocess_input = tf.keras.applications.resnet_v2.preprocess_input

"""### **4. Create base model from pre-trained convolution neural network `MobileNet V2`**"""

image_size = (img_height, img_width)

image_shape = image_size + (3,)

base_model = tf.keras.applications.ResNet50V2(input_shape = image_shape,
                                              include_top = False,
                                              weights = 'imagenet')

# iterate through train_ds and extract images, labels
image_batch, label_batch = next(iter(train_ds))

# apply base model to image_batch to extract features
feature_batch = base_model(image_batch)

# features shape
print(feature_batch.shape)

"""### **5. Feature extraction**

#### **5a.** Freeze convolutional base to use as feature extractor
"""

base_model.trainable = False


"""#### **5b.** Add a classifier on top of base model and train top-level classifier"""

# global average pooling for 7x7 spatial locations
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()

# apply layer to features
feature_batch_average = global_average_layer(feature_batch)

# shape of averaged features = (num batches, num channels)
print(feature_batch_average.shape)

"""**Add a `tf.keras.layers.Dense` layer to convert features into probabilities for 39 possible classes for each image**"""

# convert features into a single prediction per image
prediction_layer = tf.keras.layers.Dense(39, activation = "softmax")

# apply predictions to features for one batch
prediction_batch = prediction_layer(feature_batch_average)

# predictions for one batch shape = (num images in batch, 1)
print(prediction_batch.shape)

"""#### **5c.** Build the model by chaining together the data augmentation, rescaling, `base_model`, feature extractor layers using the `Keras Functional API`"""

inputs = tf.keras.Input(shape = (224, 224, 3))

x = data_augmentation(inputs)

x = preprocess_input(x)

x = base_model(x, training = False)

x = global_average_layer(x)

x = tf.keras.layers.Dropout(0.2)(x)

outputs = prediction_layer(x)

model = tf.keras.Model(inputs, outputs)

"""### **6. Compile the model**"""

base_learning_rate = 0.001

model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),
                                                   loss = "sparse_categorical_crossentropy",
                                                   metrics = ['accuracy'])

model.summary()

"""### **7. Train the model**"""

# class weights

class_weights = {0: 0.11255482156830632,
 1: 0.2283509626922154,
 2: 1.4549517760526935,
 3: 1.5249013806706115,
 4: 1.210608729692699,
 5: 1.6519764957264957,
 6: 1.752372857345233,
 7: 1.332686920922215,
 8: 1.6265614727153188,
 9: 1.6434170320180683,
 10: 1.120775573072393,
 11: 1.2893475088597042,
 12: 1.6961469902646373,
 13: 1.7427444350521275,
 14: 1.7238015607580826,
 15: 1.3383100724872876,
 16: 1.6961469902646373,
 17: 1.6961469902646373,
 18: 1.752372857345233,
 19: 0.4009854452332329,
 20: 1.1450523002869575,
 21: 1.294610151753009,
 22: 1.4616566229469456,
 23: 1.7332212414179629,
 24: 1.5322680540071845,
 25: 1.7427444350521275,
 26: 1.7238015607580826,
 27: 1.7621082621082622,
 28: 1.7238015607580826,
 29: 1.6519764957264957,
 30: 1.0862311204776958,
 31: 1.7427444350521275,
 32: 1.5701954810865701,
 33: 1.7332212414179629,
 34: 1.7621082621082622,
 35: 1.7621082621082622,
 36: 1.7621082621082622,
 37: 1.7621082621082622,
 38: 1.752372857345233}


initial_epochs = 30

# model checkpoint callback
checkpoint_filepath = '/home/cew4pf/dl_project/tmp/res_checkpoint'
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

# early stopping callback
#early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights = True)

history = model.fit(train_ds,
                    epochs = initial_epochs,
                    validation_data = validation_ds,
                    callbacks = [model_checkpoint_callback],
                    class_weight = class_weights)

model.load_weights('/home/cew4pf/dl_project/tmp/res_checkpoint')

model.evaluate(validation_ds)

"""### **8. Fine tuning**

#### **8a. Unfreeze some of the `MobileNetV2` layers to allow for training on the associated parameters**
"""

# unfreeze all layers in base model (MobileNetV2)
base_model.trainable = True

print("Number of layers in base model:", len(base_model.layers))

# fine-tune from this layer onwards
fine_tune_at = 100

# freeze all layers before 'fine_tune_at' layer --> only layers from fine_tune_at ownward trainable
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable = False

"""#### **8b. Re-compile model (but with lower learning rate to prevent overfitting)**"""

# compile the model with lower learning rate to prevent overfitting
model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate / 10),
              loss="sparse_categorical_crossentropy",
              metrics = ['accuracy'])

model.summary()

len(model.trainable_variables)

"""#### **8c. Continue training the model $\rightarrow$ start where left off previously when all layers of `MobileNetV2` frozen**"""

# continue training the model

checkpoint_filepath = '/home/cew4pf/dl_project/tmp/res_checkpoint'
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

fine_tune_epochs = 60
total_epochs = initial_epochs + fine_tune_epochs

# early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights = True)

history_fine = model.fit(train_ds,
                         epochs = total_epochs,
                         initial_epoch = history.epoch[-1],
                         validation_data = validation_ds,
                         callbacks = [model_checkpoint_callback])

model.load_weights(checkpoint_filepath)

model.evaluate(validation_ds)

#!mkdir -p saved_model
model.save('/home/cew4pf/dl_project/tmp/res_model')



